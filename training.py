# -*- coding: utf-8 -*-
"""my_email.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JvS_VyB961OEQnTIuUb0KhiXsKv2Jt52
"""

import numpy as np
import pandas as pd
import nltk

df=pd.read_csv('spam22.csv', encoding= 'latin-1')

df



"""Data **Preprocessing**"""

df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True) #drop null va;ued columns

df

df.rename(columns={'v1':'target','v2':'text'},inplace=True)
df.head()

"""Make target binary {0,1}"""

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
y='target'

df['target']=le.fit_transform(df[y])

df

df.isnull().sum()

"""NO NULL VALUES PRESENT NOW CHECKING FOR DUPLICATES"""

df.duplicated().sum()

df.drop_duplicates(inplace=True)

df.duplicated().sum()

df.shape

"""Visualize Data"""

import seaborn as sns
sns.countplot(x='target',data=df)

df['target'].value_counts()




"""Countong no of words,sentences,characters for each row"""

df['num_chars']=df['text'].apply(len)

df

df['num_words']=df['text'].apply(lambda x:len(nltk.word_tokenize(x)))

df.sample(5)

df['num_sents']=df['text'].apply(lambda x:len(nltk.sent_tokenize(x)))

df.sample(5)

df.describe()

sns.pairplot(data=df,hue='target')

import matplotlib.pyplot as plt
plt.figure(figsize=(10,5))
print(sns.histplot(x='num_chars',hue='target',data=df))
#print(sns.histplot(x='num_words',hue='target',data=df))


from nltk.corpus import stopwords
import string
from nltk.stem.porter import PorterStemmer
ps=PorterStemmer()
def transform_text(text):
    text=text.lower()
    text=nltk.word_tokenize(text)
    y=[]
    for i in text:
        if i.isalnum():
            y.append(i)
    text=y[:]
    y.clear()
    for i in text:
        if i not in stopwords.words('english') and i not in string.punctuation:
            y.append(i)
    text=y[:]
    y.clear()
    for i in text:
        y.append(ps.stem(i))

    return " ".join(y)

transform_text('I like Running, you like to run??>')

df['text'].apply(transform_text)

df['new_text']=df['text'].apply(transform_text)

df.head()

"""return all non-spam messages (ham)

to convert text data into numerical feature vectors for mdel trainin
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer

tfidf=TfidfVectorizer()
x=tfidf.fit_transform(df['new_text']).toarray()
cv= CountVectorizer()
x1=cv.fit_transform(df['new_text']).toarray()

print("tfidf:",tfidf.idf_)
print("x1:",x1)

print("tfidf:",tfidf.idf_)
print("x1:",x1)

y=df['target'].values
y

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)
x_train1,x_test1,y_train1,y_test1=train_test_split(x1,y,test_size=0.2,random_state=0)

from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB

gnb=GaussianNB()
mnb=MultinomialNB()
bnb=BernoulliNB()

from sklearn.metrics import accuracy_score,precision_score,confusion_matrix

gnb.fit(x_train,y_train)

y_pred4=gnb.predict(x_test)

accuracy_score(y_test,y_pred4)*100

precision_score(y_test,y_pred4)

confusion_matrix(y_test,y_pred4)

"""countvectorizer of gnb"""

gnb.fit(x_train1,y_train1)

y_pred1=gnb.predict(x_test1)
accuracy_score(y_test1,y_pred1)*100

precision_score(y_test1,y_pred1)

confusion_matrix(y_test1,y_pred1)

mnb.fit(x_train,y_train)
mnb.fit(x_train1,y_train1)

y_pred2=mnb.predict(x_test)
y_pred22=mnb.predict(x_test1)

print("tf:",accuracy_score(y_test,y_pred2)) # Accuracy of the model trained/tested on TF-IDF vectorized data (likely corresponding to y_test and y_pred2).
print("cv:",accuracy_score(y_test1,y_pred22))# Accuracy of the model trained/tested on CountVectorizer (BoW) data (likely corresponding to y_test1 and y_pred22).

print("p_tf:",precision_score(y_test,y_pred2))
print("p_cv:",precision_score(y_test1,y_pred22))

print("tf:",confusion_matrix(y_test,y_pred2))
print("cv:",confusion_matrix(y_test1,y_pred22))

bnb.fit(x_train,y_train)
bnb.fit(x_train1,y_train1)

y_pred3=bnb.predict(x_test)
y_pred33=bnb.predict(x_test1)

print("tf:",accuracy_score(y_test,y_pred3))
print("cv:",accuracy_score(y_test1,y_pred33))

print("tf:",precision_score(y_test,y_pred3))
print("cv:",precision_score(y_test1,y_pred33))

print("tf:",confusion_matrix(y_test,y_pred3))
print("cv:",confusion_matrix(y_test1,y_pred33))



"""WE choose multinomialNB"""

from sklearn.naive_bayes import MultinomialNB

mnb=MultinomialNB()

mnb.fit(x_train,y_train)
y_pred=mnb.predict(x_test)
accuracy=accuracy_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)



import pickle
pickle.dump(tfidf,open('vectorizer.pkl','wb'))
pickle.dump(mnb,open('model.pkl','wb'))

